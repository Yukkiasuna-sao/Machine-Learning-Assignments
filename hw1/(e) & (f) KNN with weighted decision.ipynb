{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#load train and test data\n",
    "train_data   = []\n",
    "test_data = []\n",
    "train_labels = []\n",
    "test_labels = []\n",
    "\n",
    "with open(\"train_set.txt\") as f:  \n",
    "        for line in f:\n",
    "            tokens = line.strip().split(' ')  \n",
    "            train_data.append([float(tk) for tk in tokens[:-1]])  \n",
    "            train_labels.append(int(tokens[-1]))  \n",
    "x_train = np.array(train_data)\n",
    "y_train = np.array(train_labels)\n",
    "\n",
    "with open(\"test_set.txt\") as ff:  \n",
    "        for line in ff:\n",
    "            tokens = line.strip().split(' ')  \n",
    "            test_data.append([float(tk) for tk in tokens[:-1]])  \n",
    "            test_labels.append(int(tokens[-1])) \n",
    "x_test = np.array(test_data)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Euclidean Distance, the optimal number of neighbors k in KNN is 6\n",
      "The minimal test error with Euclidean Distance is 0.10\n"
     ]
    }
   ],
   "source": [
    "#KNN in Euclidean metric with weighted decision\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "k_range = np.arange(1, 197, 5)\n",
    "#print(k_range)\n",
    "\n",
    "test_error_euclidean = []\n",
    "for k in k_range:\n",
    "   \n",
    "   knn = KNeighborsClassifier(n_neighbors = k, weights='distance')\n",
    "   knn.fit(x_train, y_train)\n",
    "   test_error_euclidean.append(1 - accuracy_score(y_test, knn.predict(x_test)))\n",
    "optimal_k_euclidean = k_range[test_error_euclidean.index(min(test_error_euclidean))]\n",
    "print('With Euclidean Distance, the optimal number of neighbors k in KNN is %d' % optimal_k_euclidean)\n",
    "print('The minimal test error with Euclidean Distance is %.2f' % min(test_error_euclidean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Manhattan Distance, the optimal number of neighbors k in KNN is 26\n",
      "The minimal test error with Manhattan Distance is 0.10\n"
     ]
    }
   ],
   "source": [
    "#KNN in Manhattan Distance with weighted decision\n",
    "\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_error_manhattan = []\n",
    "for k in k_range:\n",
    "   #distance becomes Manhattan Distance when p = 1\n",
    "   knn = KNeighborsClassifier(n_neighbors = k, p=1, metric='minkowski',weights='distance')\n",
    "   knn.fit(x_train, y_train)\n",
    "   test_error_manhattan.append(1 - accuracy_score(y_test, knn.predict(x_test)))\n",
    "optimal_k_manhattan = k_range[test_error_manhattan.index(min(test_error_manhattan))]\n",
    "\n",
    "print('With Manhattan Distance, the optimal number of neighbors k in KNN is %d' % optimal_k_manhattan)\n",
    "print('The minimal test error with Manhattan Distance is %.2f' % min(test_error_manhattan))\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(k_range, test_error, label='Test Errors')\n",
    "# # plt.vlines(optimal_k, plt.ylim()[0], np.max(test_error), linestyles = 'dashed', label='Optimal k on test')\n",
    "# plt.title('Test errors in terms of k (KNN with Manhattan Distance)')\n",
    "# plt.xlabel('Number of Neighbors - k')\n",
    "# plt.ylabel('Error rate')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Chebyshev Distance, the optimal number of neighbors k in KNN is 16\n",
      "The minimal test error with Chebyshev Distance is 0.11\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import DistanceMetric\n",
    "#KNN in Chebyshev Distance with weighted decision\n",
    "test_error_chebyshev = []\n",
    "for k in k_range:\n",
    "   knn = KNeighborsClassifier(n_neighbors = k,metric='chebyshev',weights='distance')\n",
    "   knn.fit(x_train, y_train)\n",
    "   test_error_chebyshev.append(1 - knn.score(x_test, y_test))\n",
    "optimal_k = k_range[test_error_chebyshev.index(min(test_error_chebyshev))]\n",
    "print('With Chebyshev Distance, the optimal number of neighbors k in KNN is %d' % optimal_k)\n",
    "print('The minimal test error with Chebyshev Distance is %.2f' % min(test_error_chebyshev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With mahalanobis Distance, the optimal number of neighbors k in KNN is 1\n",
      "The minimal test error with Mahalanobis Distance is 0.17\n"
     ]
    }
   ],
   "source": [
    "#KNN in Mahalanobis Distance \n",
    "import math\n",
    "import numpy as np\n",
    "test_error_mahalanobis = []\n",
    "for k in k_range:\n",
    "   knn = KNeighborsClassifier(n_neighbors = k,metric='mahalanobis',weights='distance', metric_params={'V':np.cov(np.array(x_train).T)})\n",
    "   knn.fit(x_train, y_train)\n",
    "   test_error_mahalanobis.append(1 - knn.score(x_test, y_test))\n",
    "optimal_k = k_range[test_error_mahalanobis.index(min(test_error_mahalanobis))]\n",
    "print('With mahalanobis Distance, the optimal number of neighbors k in KNN is %d' % optimal_k)\n",
    "print('The minimal test error with Mahalanobis Distance is %.2f' % min(test_error_mahalanobis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lowest training error rate achieved in this exercise is 0 when k=1 since the nearest neighbor is the point itself\n"
     ]
    }
   ],
   "source": [
    "print('The lowest training error rate achieved in this exercise is 0 when k=1 since the nearest neighbor is the point itself')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0a3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
